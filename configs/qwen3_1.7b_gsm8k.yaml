# Qwen3-1.7B GRPO on GSM8K - Memory Optimized Config
reference_model_config:
  model_name: "qwen3-1.7b"
  model_id: "Qwen/Qwen3-1.7B"
  model_source: "huggingface"
  mesh:
    shape: "(8,1)"
    axis_names: "('fsdp','tp')"

actor_model_config:
  mesh:
    shape: "(8,1)"  # Full FSDP for memory efficiency
    axis_names: "('fsdp','tp')"

rollout_model_config:
  mesh:
    shape: "(8,1)"  # Full FSDP/DP for rollout throughput
    axis_names: "('fsdp','tp')"

tokenizer_config:
  tokenizer_path: "Qwen/Qwen3-1.7B"
  tokenizer_type: "huggingface"

dataset_name: "gsm8k"
data_source: "tfds"

batch_size: 16

grpo_config:
  num_generations: 8
  num_iterations: 1
  beta: 0.08
  epsilon: 0.2

rollout_config:
  total_generation_steps: 2048
  max_prompt_length: 256
  temperature: 0.9
  top_p: 1.0
  top_k: 50

rl_training_config:
  actor_optimizer_config:
    opt_type: "adamw"
    peak_value: 3e-6
    init_value: 0.0
    end_value: 0.0
    schedule_type: "warmup_cosine_decay_schedule"
    warmup_ratio: 0.1
    warmup_steps: 10
    decay_steps: 100
    b1: 0.9
    b2: 0.99
    weight_decay: 0.1
    max_grad_norm: 0.1
  metrics_logging_options:
    project_name: "qwen3-grpo-gsm8k"
    run_name: "qwen3-1.7b-grpo"
    log_dir: "/tmp/tensorboard/grpo_qwen3"
  eval_every_n_steps: 10

reward_functions:
  - "plugin/reward_fn/gsm8k_qwen3.py"
